{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Supervised Learning on Social Media Posts: Mental Health Disorder Classification\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Gilberto Robles\n",
    "- Soyon Kim\n",
    "- Allan Tan\n",
    "- Jason Sheu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "Mental health patients struggle with financial, psychological, and logistical burden when seeking professional help. As such, social media, particularly Reddit, has become a popular outlet for people to ask questions anonymously for help. In order to aid mental healthcare become accessible and affordable online, we aim to use supervised machine learning to detect self-harming and destructive behavior as well as classify potential mental disorders using the DSM-5 (Diagnostic and Statistical Manual of Mental Disorders) Diagnostic Criteria. Our model could also be utilized in a professional environment by assisting care providers with diagnostic information. Additionally, the practicality of this experiment would extend into the implementation of notification alerts to reddit users privately, if their posts are detected to have a potential for self-harm or a diagnosis of a mental disorder. \n",
    "\n",
    "We use the Reddit Mental Health Dataset, which consists of posts from 28 different subreddits (15 mental health support groups) from 2018-2020. In our methods, we deploy a Self-Supervised Text-Classification model with TensorFlow to allow us to create a labeled dataset. Further, we implement two Multi-Class Text Classification models in a cross-examination study to evaluate the performance difference between K-Nearest Neighbors and Support Vector Machines to find patterns in people seeking support in mental health related subreddits. The posts will thus be related to mental disorders and harmful behavior in order to potentially diagnose (or at least warn) users about the content of their posts, and then direct them to helpful resources in an accessible, private, and preventative manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "### The Mental Health Epidemic\n",
    "The current mental healthcare system places various financial, psychological, and logistical burdens on those seeking professional help for their mental disorders.\n",
    "To list a few:\n",
    "- There is a huge shortage of therapists/psychiatrists, leading to months and even year-long waitlists for an incoming patient’s first appointment. Especially since many do not accept insurance, this causes a huge difficulty in patients finding connection to clinicians in the first place.\n",
    "- There is a strong social stigma against seeking professional help for mental disorders. That is, the fear of admitting to one’s issues and becoming labeled as “disabled” leads to anosognosia, or the denial or “lack of insight” in acknowledging one’s mental health issues.\n",
    "- There is also the burden on incoming patients to find the best-fitting therapist in terms of location, specialization, cost, gender, age, and culture. When switching clinicians, the psychological burden of repeated intake sessions where one must elaborate on their mental health history can also be extremely cumbersome.\n",
    "\n",
    "### Previous Research: Machine Learning and Mental Health\n",
    "As a result of this lack of outlet for mental health struggles, many turn to the internet to anonymously confess their difficulties and build communities for support. Low et al. for example, the developer of our dataset for this project, performed an an observational study with natural language processing to reveal vulnerable mental health support groups and heightened health anxiety on Reddit during COVID-19. Meanwhile, Human-Machine Interaction (HMI) is the field that explores computer and robot technology that focuses on the relationship between people and machines. As closely related to humans, HMI has focused on enhancing human health, particularly mental health. \n",
    "\n",
    "For example, \n",
    "- Chikersal et al. developed automatic Depression detection through machine learning of biosensor feedback [2]. There are also various products in the market that use machine learning and other intelligent methods for user personalization in preference and treatment. For example, there are mobile apps including mindfulness apps like Headspace, Calm, and UCLA Mindful and therapeutic robots like Paro, Hugvie, Pepper, Carebot, and QTRobot [4, 5].\n",
    "- Cheng et al. created \"Psychologist in a Pocket\", a Lexicon Development and Content Validation of a Mobile-Based App for Depression Screening\n",
    "\n",
    "For the development of our project and our own lexicon, we also consulted Li et al. Automatic Construction of a Depression-Domain Lexicon Based on Microblogs: Text Mining Study, as well as \"Lexicon-based method to detect signs of depression in text\" on GitHub by Pablo Gamallo.\n",
    "\n",
    "Additionally, during the development of our Self-Supervised Model for text classification, we consulted with Keras documentation, \"End-to-end Masked Language Modeling with BERT\" to train a language model in a self-supervised setting (without human-annotated labels).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In this project, we want to tackle the problem of lack of accessible, affordable, and preventative mental health support resources through the use of popular social media sites. Specifically, we want to assist Internet users struggling with mental disorders who have exhibited a range of qualifying behavior traits, as per DSM-5, through the use of an automated system that classifies them based on their Reddit posts. The most challenging aspect of this, is that our dataset did not come pre-labeled for ease of access, and every resource we consulted had private lexicon datasets, which were not accessible to us. For this reason we decided to develop a Masked Language Model to self-supervise our data, and create automatic labels, which we would later divide into training and testing to compare different model performances.\n",
    "\n",
    "The system would learn words or phrases commonly used by people with the qualifying criteria versus people who do not exhibit any concern within the same Reddit thread, with the use of KNN and SVM text classification models. That is, the system would learn words and phrases used by people who clearly exhibit behavior and meet the criteria for mental disorders. Then, given a reddit post, the system will try to detect whether the post meets concerning criteria, at which point the user will be notified and directed to relevant resouces. For this project, we aim to primarily focus on a single model that can differentiate between people that display signs of mental illness versus those that do not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Link to dataset: https://zenodo.org/record/3941387/files/depression_2018_features_tfidf_256.csv?download=1\n",
    "\n",
    "Dataset size: 24535 rows, 350 columns. Many of these columns are tf-idf statistics that we will not be using. The column that we are interested in is primarily the 'post' column, which is the column containing the text of the post made by a user.\n",
    "\n",
    "The dataset we plan to use is text that was scraped from Reddit’s mental health support subreddits. The link to the dataset can be found as item 3 in the footnotes [3]. The data was originally created to examine the effects of COVID-19 on mental health. It contains posts from 28 different subreddits, or 15 mental health support groups, and dates range from 2018-2020. The link provided includes a variety of mental health disorders.\n",
    "\n",
    "For our project in particular, we will be analyzing the posts associated with self-harming behavior as per DSM-5 criteria. As a result, the data we will be examining are for example, in the case of \"Major depressive disorder\", would be\n",
    "- depression_2018_features_tfidf_256.csv\n",
    "- depression_2019_features_tfidf_256.csv\n",
    "- etc.\n",
    "\n",
    "Regarding these two datasets in particular, the each have about 24500 and 33500 observations, respectively. They also have a wide array of variables concerning the text and the text’s metadata. Examples include:\n",
    "- the subreddit the text was scraped from\n",
    "- the username of the poster\n",
    "- actual text itself\n",
    "- date posted\n",
    "- unique words\n",
    "- syllables\n",
    "\n",
    "In total there are 350 variables for one observation. Similarly, a single observation basically constitutes a post on the subreddit would have all of the aforementioned variables. Because our project revolves around textual analysis and classification, we will predominantly focus on the reddit post's text portion of each observation. As a result, some critical variables are:\n",
    "- the text of the post\n",
    "- the date it was posted\n",
    "- number of words\n",
    "- number of times a “trigger” word such as gun or suicide is used, etc.\n",
    "\n",
    "The text of the post will be in string format and the date will also be a string in MM/DD/YYYY format. Other variables will be in integer or float format as they are primarily responsible for keeping track of word frequencies. Because we are only using a few of the variables out of the 350 available, we will need to remove the unnecessary ones. Additionally, to preserve anonymity, we will be removing the author variable from each observation. Some additional cleaning could also take the form of removing special characters from the text of each observation or making all characters lowercase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
